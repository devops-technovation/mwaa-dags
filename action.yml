name: "Dags Deployment"

inputs:
  division:
    description: 'Division Name'
    required: false
    default: div
  region:
    description: 'AWS Region'
    required: false
    default: us-east-1
  data_type:
    description: 'Data type'
    required: false
    default: analytics
  sec_type:
    description: 'Seccion Type'
    required: false
    default: core
  bucket_name:
    description: 'Name of the Airflow bucket'
    required: false
    default: dev
  dags_path:
    description: 'Name of the folder where will be stored the dags'
    required: false
    default: dags

outputs:
  role_name:
    description: "The role to be used for OIDC auth"
    value: ${{ steps.validate_changes.outputs.role_name }}
  bucket_url:
    description: "The bucket where will uploaded the dags"
    value: ${{ steps.validate_changes.outputs.bucket_url }}
  modified:
    description: "Whether there are new or updated dags to plublish to S3"
    value: ${{ steps.validate_changes.outputs.modified }}

runs:
  using: "composite"
  steps:

    - name: Validate changes
      shell: bash
      id: validate_changes
      run: |
        echo "github sha: ${{github.sha}}"
        echo "files changed: "  $(git show --stat --oneline  ${{ github.sha }})
        for file in $(git show --stat --oneline  ${{ github.sha }}); do
          if [[ $file == *".py" ]]; then
              dir=$(dirname "${file}")
              env_prefix=$(echo "${dir}" | head -c 1)
              datatype_prefix=$(echo "${{inputs.data_type}}" | head -c 1)
              sectype_prefix=$(echo "${{inputs.sec_type}}" | head -c 1)
              BUCKET_NAME="${{inputs.division}}-${{inputs.region}}-${env_prefix}${datatype_prefix}${sectype_prefix}-${{inputs.bucket_name}}"
              if [[ $dir == "prod" ]]; then
                ACCOUNT_ID=12345
              else
                ACCOUNT_ID=67890
              fi
              ROLE_NAME="arn:aws:iam::${ACCOUNT_ID}:role/${{inputs.division}}-${{inputs.region}}-${dir}-mwaa-dev-uploader"
              echo "::set-output name=role_name::$ROLE_NAME"
              echo "::set-output name=bucket_url::$BUCKET_NAME"
              echo "::set-output name=modified::true"
              
          fi
        done
        
    - name: check output
      shell: bash
      run: |
        echo "modified ?: " ${{ steps.validate_changes.outputs.modified }}
        
    #     - name: Auth to  AWS
#       uses: devops-technovation/actions-aws-auth@main
#       with:
#         role: "${{steps.validate_changes.outputs.role_name}}"
#     - run: aws sts get-caller-identity

#     - name: Configure AWS credentials
#       uses: aws-actions/configure-aws-credentials@v1
#       with:
#         role-to-assume: arn:aws:iam::053342002484:role/github-oidc
#         aws-region: us-east-1
          
    - uses: hashicorp/setup-terraform@v1
      with:
        terraform_version: 1.2.1
        terraform_wrapper: false
         
    - name: upload Dags to S3
      shell: bash
      run: |
        if [[ "${{ steps.validate_changes.outputs.modified }}" == "true" ]]; then
          echo "role_name:  ${{steps.validate_changes.outputs.role_name}}"
          echo "aws s3 cp $file s3://${{ steps.validate_changes.outputs.bucket_url }}/dag/"
        fi
